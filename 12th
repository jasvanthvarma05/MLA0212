import numpy as np
import pandas as pd

# Generating synthetic data
np.random.seed(42)
hours_studied = np.random.randint(1, 10, 100)
marks = 2.5 * hours_studied + np.random.normal(0, 2, 100)  # Linear relation with some noise

# Convert to DataFrame
data = pd.DataFrame({'Hours_Studied': hours_studied, 'Marks': marks})
data['Pass'] = data['Marks'].apply(lambda x: 1 if x >= 50 else 0)  # Assuming 50 is the passing mark

# Inspect the dataset
print(data.head())

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# Split the dataset into training and testing sets
X = data[['Hours_Studied']]
y = data['Marks']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Linear Regression model
linear_reg = LinearRegression()
linear_reg.fit(X_train, y_train)

# Predict on the test set
y_pred_linear = linear_reg.predict(X_test)

# Plot Linear Regression
plt.scatter(X_test, y_test, color='blue', label='Actual Marks')
plt.plot(X_test, y_pred_linear, color='red', label='Linear Regression')
plt.xlabel('Hours Studied')
plt.ylabel('Marks')
plt.title('Linear Regression')
plt.legend()
plt.show()
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Train the Polynomial Regression model (degree 2 for simplicity)
poly_features = PolynomialFeatures(degree=2)
poly_reg_model = make_pipeline(poly_features, LinearRegression())
poly_reg_model.fit(X_train, y_train)

# Predict on the test set
y_pred_poly = poly_reg_model.predict(X_test)

# Plot Polynomial Regression
plt.scatter(X_test, y_test, color='blue', label='Actual Marks')
plt.scatter(X_test, y_pred_poly, color='green', label='Polynomial Regression', alpha=0.7)
plt.xlabel('Hours Studied')
plt.ylabel('Marks')
plt.title('Polynomial Regression')
plt.legend()
plt.show()
from sklearn.linear_model import LogisticRegression

# Logistic Regression to classify Pass/Fail
X = data[['Hours_Studied']]
y = data['Pass']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Logistic Regression model
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)

# Predict on the test set
y_pred_log = log_reg.predict(X_test)

# Plot Logistic Regression
plt.scatter(X_test, y_test, color='blue', label='Actual Pass/Fail')
plt.scatter(X_test, y_pred_log, color='red', label='Logistic Regression', alpha=0.7)
plt.xlabel('Hours Studied')
plt.ylabel('Pass/Fail')
plt.title('Logistic Regression')
plt.legend()
plt.show()
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report

# Linear Regression Evaluation
mse_linear = mean_squared_error(y_test, y_pred_linear)
r2_linear = r2_score(y_test, y_pred_linear)
print(f'Linear Regression - MSE: {mse_linear}, R2: {r2_linear}')

# Polynomial Regression Evaluation
mse_poly = mean_squared_error(y_test, y_pred_poly)
r2_poly = r2_score(y_test, y_pred_poly)
print(f'Polynomial Regression - MSE: {mse_poly}, R2: {r2_poly}')

# Logistic Regression Evaluation
accuracy_log = accuracy_score(y_test, y_pred_log)
class_report_log = classification_report(y_test, y_pred_log)
print(f'Logistic Regression - Accuracy: {accuracy_log}')
print('Classification Report:')
print(class_report_log)


"""
   Hours_Studied      Marks  Pass
0              7  18.153690     0
1              4   9.837762     0
2              8  20.935590     0
3              5  13.972245     0
4              7  15.940596     0
"""
